
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>14.11. JNB Lab Solutions &#8212; An Introduction to Python Jupyter Notebooks for College Math Teachers</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=07d05eac" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Advanced/AdvDataAnalysis/nlp_lab_solutions';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="15. COMPLEX SYSTEMS - Wheaton College Team" href="../../ComplexSystems.html" />
    <link rel="prev" title="14.10. JNB Lab: United States Grant Data" href="nlp_lab.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="An Introduction to Python Jupyter Notebooks for College Math Teachers - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="An Introduction to Python Jupyter Notebooks for College Math Teachers - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    An Introduction to Python Jupyter Notebooks for College Math Teachers
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Preface.html">1. PREFACE</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../JMM23.html">1.1. JMM 2023</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lab.html">1.2. JNB LAB: Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../labsolutions.html">1.3. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../PreCollege.html">2. PRE-COLLEGE - Wheaton College Team</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../PreCollege/PreCollegeIntro.html">2.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Elementary/Arithmetic/elementary.html">2.2. Elementary Blackboard Problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../PreCollege/GettingStarted/python.html">2.3. Beginning Python Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../PreCollege/Celestial/Chicago.html">2.4. Glimpse of Chicago</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../PreCollege/Celestial/steam.html">2.5. Arts in STEM (STEAM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../PreCollege/solutions.html">2.6. Solution to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../PreCollege/Celestial/demo.html">2.7. JNB LAB: After-School Program Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../PreCollege/Celestial/demosolutions.html">2.8. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Intropy.html">3. PYTHON PROGRAMMING GUIDE - Thomas VanDrunen, Yiheng Liang</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Programming/PythonProgrammingGuideIntro.html">3.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Programming/Introduction_to_Python.html">3.2. Introduction to Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Programming/Data.html">3.3. Working with Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Programming/solutions.html">3.4. Solution to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Programming/Plab.html">3.5. JNB Lab: Introduction to Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Programming/Plabsolutions.html">3.6. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Data.html">4. EXPLORATORY DATA ANALYSIS - Jonathan Zhu</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/sec1_basic_intro.html">4.1. Introduction to Part I</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/sec2_basic_tabular.html">4.2. Data Investigation I</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/sec3_basic_plotting.html">4.3. Plotting and Statistical Testing I</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/sec4_basic_solutions.html">4.4. Solutions to Part I Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/sec5_advanced_intro.html">4.5. Introduction to Part II</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/sec6_advanced_tabular.html">4.6. Data Investigation II</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/sec7_advanced_plotting.html">4.7. Plotting and Statistical Testing II</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/sec8_advanced_report.html">4.8. Making EDA Reports</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/sec9_advanced_solution.html">4.9. Solutions to Part II Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/lab.html">4.10. JNB Lab: Housing Equity Initiative</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/EDA/labsolution.html">4.11. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Prob.html">5. PROBABILITY - Laura Gross, Yiheng Liang</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/prob.html">5.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/prob1.html">5.2. Random Numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/prob2.html">5.3. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/prob3.html">5.4. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/prob4.html">5.5. Probability Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/prob4a.html">5.6. Random Walks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/prob5.html">5.7. Agent-based Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/prob6.html">5.8. Mathematical Games</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/solutions.html">5.9. Solution to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/lab.html">5.10. JNB Lab: Homicides in Chicago</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/ProbIntro/labsolution.html">5.11. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Stat.html">6. STATISTICAL INFERENCE - Peter Jantsch, Claire Wagner</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/StatInf/00_Instructor_Notes.html">6.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/StatInf/01_Foundations.html">6.2. Foundations of Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/StatInf/02_Inference_Categorical.html">6.3. Hypothesis Testing for Categorical Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/StatInf/03_Inference_Numerical.html">6.4. Hypothesis Testing for Numerical Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/StatInf/04_Regression.html">6.5. Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/StatInf/Solutions.html">6.6. Solutions to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/StatInf/05_Lab.html">6.7. JNB Lab: The Framingham Heart Study</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ProbStat/StatInf/05_Lab_Solutions.html">6.8. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../AppliedCalc.html">7. APPLIED CALCULUS FOR DAILY LIFE - Wheaton College Team</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/AppliedCalculusIntro.html">7.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/twocommodity.html">7.2. Linear Systems and the Two-commodity Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/marginal.html">7.3. Marginal and Average Cost</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/design.html">7.4. Optimization and Object Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/cobbs.html">7.5. Optimization and Cobbs-Douglas Production</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/rates.html">7.6. Related Rates and Volumes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/football.html">7.7. Related Rates with Trig Functions and Football</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/jnb7.html">7.8. Probability Distributions and Drive Thrus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/control.html">7.9. Normal Distribution and Process Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/ols.html">7.10. Partial Derivatives and OLS Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/gini.html">7.11. Area Between Curves and the Gini Index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/income.html">7.12. Integral Test and Income Streams</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/ode.html">7.13. Ordinary Differential Equations and Exponential Growth/Decay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/solutions.html">7.14. Solutions to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/AClab.html">7.15. JNB Lab: Calculus of Entropy in Daily Life and Monte Carlo Simulations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedCalc/AClabsolutions.html">7.16. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Calc.html">8. CALCULUS - Inne Singgih</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/Intro.html">8.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/2Functions.html">8.2. Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/3Limits.html">8.3. Limits, Continuity, and Rates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/4%20Derivatives.html">8.4. Derivatives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/5%20Integrals.html">8.5. Integrals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/6%20ParametricEquations.html">8.6. Parametric Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/7%20Sequences%20and%20Series.html">8.7. Sequences and Series</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/Solutions.html">8.8. Solution to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/clab.html">8.9. JNB LAB: Calculus Animations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Calculus/clabsolution.html">8.10. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Linear.html">9. LINEAR ALGEBRA - Soheil Anbouhi</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Linear/0.html">9.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Linear/1.html">9.2. Linear Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Linear/2.html">9.3. Matrices and Determinants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Linear/3.html">9.4. Linear Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Linear/4.html">9.5. Eigenvalues and Eigenvectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Linear/5.html">9.6. Orthogonality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Linear/Solutions.html">9.7. Solutions to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Linear/LAlab.html">9.8. JNB Lab: Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/Linear/LAlabsolutions.html">9.9. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Aplin.html">10. LINEAR ALGEBRA AND OPTIMIZATION FOR DATA ANALYSIS - Wheaton College Team</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../LinearAlgebra/Introduction.html">10.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../LinearAlgebra/OLS/jnb1.html">10.2. OLS Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../LinearAlgebra/KMeans/jnb2.html">10.3. K-means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../LinearAlgebra/PCA/jnb3.html">10.4. Dimension Reduction by Principal Component Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../LinearAlgebra/SVM/jnb4.html">10.5. Binary Classification of Labeled Data by Support Vector Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../LinearAlgebra/solutions.html">10.6. Solution to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../LinearAlgebra/ALlab.html">10.7. JNB LAB: Linear Algebra for Data Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../LinearAlgebra/ALlabsolution.html">10.8. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../DifEq.html">11. DIFFERENTIAL EQUATIONS - Rachel Petrik</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/DifEq/Differential%20Equations.html">11.1. Overview of Chapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/DifEq/DE2.html">11.2. Introduction to Differential Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/DifEq/DE3.html">11.3. First-Order Differential Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/DifEq/DE4.html">11.4. Second-Order Differential Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/DifEq/DE5.html">11.5. Systems of First-Order Differential Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/DifEq/DE6.html">11.6. Laplace Transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/DifEq/DESolutions.html">11.7. Solutions to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/DifEq/Differential%20Equations%20Book%201%20Lab.html">11.8. JNB Lab: Differential Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/DifEq/Differential%20Equations%20Book%201%20Lab%20Answer%20Key.html">11.9. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../AppliedDifEq.html">12. DIFFERENTIAL EQUATIONS FOR THE BENEFIT OF SOCIETY - Wheaton College Team</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/AppliedDiffEqIntro.html">12.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/covid.html">12.2. Logistic Growth and COVID-19</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/sir.html">12.3. The Basic SIR Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/cholera.html">12.4. Cholera in Haiti</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/cws/cws.html">12.5. CWS Model of Alzheimer’s Disease</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/gravity/gravity.html">12.6. Gravity Fed Water Delivery</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/erc/erc.html">12.7. Earthquake Resistant Construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/solutions.html">12.8. Solutions to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/hiv/lab.html">12.9. JNB Lab: HIV-AIDS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Undergrad/AppliedDifEq/labsolutions.html">12.10. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../ComplexVar.html">13. COMPLEX VARIABLES IN GROUNDWATER MODELING - Wheaton College Team</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Complex/complex_variables_1.html">13.1. Setting the Scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Complex/complex_variables_2.html">13.2. Complex Analysis Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Complex/complex_variables_3.html">13.3. Idealized Groundwater Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Complex/complex_variables_4.html">13.4. Contaminant Extraction Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Complex/complex_variables_solutions.html">13.5. Solutions to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Complex/complex_variables_lab.html">13.6. JNB LAB: Complex Potentials and Contaminant Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Complex/complex_variables_lab_solution.html">13.7. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../AdvData.html">14. ADVANCED DATA ANALYSIS - Jonathan Zhu, Claire Wagner, Ying Li</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="sec0_data.html">14.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="sec1_preprocessing.html">14.2. Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="sec2_transform_features.html">14.3. About Text Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="sec3_doc_embedding.html">14.4. Document Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="sec4_classification_algos.html">14.5. Classification of Texts</a></li>
<li class="toctree-l2"><a class="reference internal" href="sec5_classification_eval.html">14.6. Evaluating Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="sec6_applications.html">14.7. Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="solutions_sec1-4.html">14.8. Solutions to Exercises: Sections 1 to 4</a></li>
<li class="toctree-l2"><a class="reference internal" href="solutions_sec5-7.html">14.9. Solutions to Exercises: Sections 5 to 7</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_lab.html">14.10. JNB Lab: United States Grant Data</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">14.11. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../ComplexSystems.html">15. COMPLEX SYSTEMS - Wheaton College Team</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ComplexSystems/complex_systems_1.html">15.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ComplexSystems/complex_systems_2.html">15.2. Fundamental Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ComplexSystems/complex_systems_3.html">15.3. Mathematical Concepts from Equilibrium Statistical Physics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ComplexSystems/complex_systems_4.html">15.4. Societal Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ComplexSystems/complex_systems_solutions.html">15.5. Solution to Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ComplexSystems/complex_systems_lab.html">15.6. JNB LAB: Complex Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ComplexSystems/complex_systems_labsolution.html">15.7. JNB Lab Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/timothyprojectGiG/JB_Math_Textbook/main?urlpath=tree/src/Advanced/AdvDataAnalysis/nlp_lab_solutions.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/timothyprojectGiG/JB_Math_Textbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/timothyprojectGiG/JB_Math_Textbook/issues/new?title=Issue%20on%20page%20%2FAdvanced/AdvDataAnalysis/nlp_lab_solutions.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/Advanced/AdvDataAnalysis/nlp_lab_solutions.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>JNB Lab Solutions</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-exercises-part-1-supervised-learning-and-vectorizations">14.11.1. Lab Exercises, Part 1: Supervised Learning and Vectorizations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unsupervised-learning">14.11.2. Unsupervised Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-exercises-part-2-unsupervised-learning">14.11.3. Lab Exercises, Part 2: Unsupervised Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-exercises-part-3-similarity">14.11.4. Lab Exercises, Part 3: Similarity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-ai-and-language-models">14.11.5. Generative AI and Language Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-exercises-part-4-generative-ai-and-language-models">14.11.6. Lab Exercises, Part 4: Generative AI and Language Models</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="jnb-lab-solutions">
<h1><span class="section-number">14.11. </span>JNB Lab Solutions<a class="headerlink" href="#jnb-lab-solutions" title="Link to this heading">#</a></h1>
<p>The United States publishes government grant opportunities to solicit eligible opportunities. The dataset of grant opportunities is updated every day and can be found at <a class="reference external" href="https://www.grants.gov/xml-extract">https://www.grants.gov/xml-extract</a> to be downloaded as an xml file. In this lab, we will be classifying these grant entries into the various UN SDG goals that we talked about throughout the chapter.</p>
<section id="lab-exercises-part-1-supervised-learning-and-vectorizations">
<h2><span class="section-number">14.11.1. </span>Lab Exercises, Part 1: Supervised Learning and Vectorizations<a class="headerlink" href="#lab-exercises-part-1-supervised-learning-and-vectorizations" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">pandas</span></code> to read in the provided xml file, which is from June 25, 2024, when this lab was first being started. You can use xml files from other days, but the solutions and exercises for this lab are based off of this file.</p></li>
</ol>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#reading the xml file</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_xml</span><span class="p">(</span><span class="s2">&quot;GrantsDBExtract20240625v2.xml&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we’ve read in the data, we can take a look at it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>OpportunityID</th>
      <th>OpportunityTitle</th>
      <th>OpportunityNumber</th>
      <th>OpportunityCategory</th>
      <th>FundingInstrumentType</th>
      <th>CategoryOfFundingActivity</th>
      <th>CategoryExplanation</th>
      <th>CFDANumbers</th>
      <th>EligibleApplicants</th>
      <th>AdditionalInformationOnEligibility</th>
      <th>...</th>
      <th>CloseDateExplanation</th>
      <th>OpportunityCategoryExplanation</th>
      <th>EstimatedSynopsisPostDate</th>
      <th>FiscalYear</th>
      <th>EstimatedSynopsisCloseDate</th>
      <th>EstimatedSynopsisCloseDateExplanation</th>
      <th>EstimatedAwardDate</th>
      <th>EstimatedProjectStartDate</th>
      <th>GrantorContactName</th>
      <th>GrantorContactPhoneNumber</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>262148</td>
      <td>Establishment of the Edmund S. Muskie Graduate...</td>
      <td>SCAPPD-14-AW-161-SCA-08152014</td>
      <td>D</td>
      <td>CA</td>
      <td>O</td>
      <td>Public Diplomacy</td>
      <td>19.040</td>
      <td>25.0</td>
      <td>Eligibility for U.S. institutions is limited t...</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>262149</td>
      <td>Eradication of Yellow Crazy Ants on Johnston A...</td>
      <td>F14AS00402</td>
      <td>D</td>
      <td>CA</td>
      <td>NR</td>
      <td>None</td>
      <td>15.608</td>
      <td>99.0</td>
      <td>The recipient has already been selected for th...</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>131073</td>
      <td>Cooperative Ecosystem Studies Unit, Piedmont S...</td>
      <td>G12AS20003</td>
      <td>D</td>
      <td>CA</td>
      <td>ST</td>
      <td>None</td>
      <td>15.808</td>
      <td>25.0</td>
      <td>This financial assistance opportunity is being...</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>131094</td>
      <td>Plant Feedstock Genomics for Bioenergy:  A Joi...</td>
      <td>DE-FOA-0000598</td>
      <td>D</td>
      <td>G</td>
      <td>ST</td>
      <td>None</td>
      <td>81.049</td>
      <td>99.0</td>
      <td>DOE Eligibility Criteria: Applicants from U.S....</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>4</th>
      <td>131095</td>
      <td>Management of HIV-Related Lung Disease and Car...</td>
      <td>RFA-HL-12-034</td>
      <td>D</td>
      <td>G</td>
      <td>HL</td>
      <td>None</td>
      <td>93.838</td>
      <td>25.0</td>
      <td>Other Eligible Applicants include the followin...</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 38 columns</p>
</div></div></div>
</div>
<ol class="arabic simple" start="2">
<li><p>What variable seems to be the best for which to classify these grant applications into various UN SDGs?</p></li>
<li><p>Take the variable you’ve chosen above and transform it into a bag of words matrix.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">OpportunityTitle</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">cv_fit</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>

<span class="n">cv_fit</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;78106x24535 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
	with 762851 stored elements in Compressed Sparse Row format&gt;
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="4">
<li><p>From the bag of words that you’ve made, identify the first ten features and print them out.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_names</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
<span class="n">feature_names</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;000&#39;, &#39;000001&#39;, &#39;000001azerbaijan&#39;, &#39;000002&#39;, &#39;000003&#39;, &#39;000008&#39;,
       &#39;00001&#39;, &#39;000011&#39;, &#39;00001395&#39;, &#39;00002413&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="5">
<li><p>Refer to the <a class="reference internal" href="sec2_transform_features.html"><span class="std std-doc">section on Document-Term Matrices</span></a> to create another vectorization of the documents. Show features 100-110.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
<span class="n">count_vector</span> <span class="o">=</span> <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">count_vector_df_unigram</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">count_vector</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">count_vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
<span class="n">term_freq</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;term&quot;</span><span class="p">:</span> <span class="n">count_vector_df_unigram</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="s2">&quot;freq&quot;</span> <span class="p">:</span> <span class="n">count_vector_df_unigram</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)})</span>
<span class="n">count_vector_df_unigram</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="n">term_freq</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;freq&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">term</span><span class="p">]</span> <span class="c1"># take a portion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>program</th>
      <th>research</th>
      <th>clinical</th>
      <th>national</th>
      <th>fy</th>
      <th>trial</th>
      <th>health</th>
      <th>grants</th>
      <th>development</th>
      <th>education</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>100</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>101</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>102</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>103</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>104</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>105</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>106</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>107</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>108</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>109</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>110</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ol class="arabic simple" start="6">
<li><p>(Bonus, if you have a strong computer) Create yet another vectorization, similar to the above, but using bigrams. Again, show features 100-110.</p></li>
</ol>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#DO NOT RUN THIS CELL UNLESS YOU HAVE BEEFY COMPUTER</span>

<span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span> 
<span class="n">count_vector</span> <span class="o">=</span> <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<span class="n">count_vector_df_bigram</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">count_vector</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">count_vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
<span class="n">term_freq</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;term&quot;</span><span class="p">:</span> <span class="n">count_vector_df_bigram</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="s2">&quot;freq&quot;</span> <span class="p">:</span> <span class="n">count_vector_df_bigram</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)})</span>
<span class="n">count_vector_df_bigram</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="n">term_freq</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;freq&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">term</span><span class="p">]</span> <span class="c1"># take a portion</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="7">
<li><p>Once again, make another vectorization, using the TF-IDF Vectorizer. Show features 100-110.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
<span class="n">tfidf_vector</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">tfidf_vector_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tfidf_vector</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
<span class="n">term_freq</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;term&quot;</span><span class="p">:</span> <span class="n">tfidf_vector_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="s2">&quot;freq&quot;</span> <span class="p">:</span> <span class="n">tfidf_vector_df</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)})</span>
<span class="n">tfidf_vector_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">110</span><span class="p">:</span><span class="mi">120</span><span class="p">,</span><span class="n">term_freq</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;freq&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">term</span><span class="p">]</span> <span class="c1"># take a portion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>program</th>
      <th>research</th>
      <th>national</th>
      <th>clinical</th>
      <th>grants</th>
      <th>fy</th>
      <th>health</th>
      <th>development</th>
      <th>cooperative</th>
      <th>trial</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>110</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.273389</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>111</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>112</th>
      <td>0.167061</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>113</th>
      <td>0.200372</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>114</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.161333</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>115</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>116</th>
      <td>0.000000</td>
      <td>0.133704</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>117</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.148290</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>118</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>119</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.304318</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>120</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ol class="arabic simple" start="8">
<li><p>Using the function you made in Exercise 4 from Section 5, modify it so as to train a model on 90% of the UNSDG dataset. Then, use this model to assign predicted classes to each of the entries in the dataset using the Perceptron, Naive Bayes, and Ridge Classifier models.</p></li>
</ol>
<p><em>This solution only uses Naive Bayes for simplicity; the other algorithms can easily replace the</em> <code class="docutils literal notranslate"><span class="pre">nb</span></code> <em>variable in this solution.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># change this to your own data directory</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;data/&quot;</span>

<span class="c1"># read and preprocess data</span>
<span class="n">text_file_name</span> <span class="o">=</span> <span class="s2">&quot;osdg-community-data-v2023-01-01.csv&quot;</span>
<span class="n">text_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_dir</span> <span class="o">+</span> <span class="n">text_file_name</span><span class="p">,</span><span class="n">sep</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span>  <span class="n">quotechar</span><span class="o">=</span><span class="s1">&#39;&quot;&#39;</span><span class="p">)</span>
<span class="n">col_names</span> <span class="o">=</span> <span class="n">text_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">text_df</span><span class="p">[</span><span class="n">col_names</span><span class="p">]</span> <span class="o">=</span> <span class="n">text_df</span><span class="p">[</span><span class="n">text_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)))</span>
<span class="n">text_df</span> <span class="o">=</span> <span class="n">text_df</span><span class="o">.</span><span class="n">astype</span><span class="p">({</span><span class="s1">&#39;sdg&#39;</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="s1">&#39;labels_negative&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="s1">&#39;labels_positive&#39;</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="s1">&#39;agreement&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">},</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">text_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">text_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">text_df</span> <span class="o">=</span> <span class="n">text_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;agreement &gt; 0.5 and (labels_positive - labels_negative) &gt; 2&quot;</span><span class="p">)</span>
<span class="n">text_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">text_df</span><span class="o">.</span><span class="n">text</span>
<span class="n">categories</span> <span class="o">=</span> <span class="n">text_df</span><span class="o">.</span><span class="n">sdg</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> \
    <span class="n">train_test_split</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">categories</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="n">X_train_count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">stop_words</span> <span class="o">=</span> <span class="s2">&quot;english&quot;</span> <span class="p">)</span>
<span class="n">X_train_count_vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>  
<span class="n">X_train_count_vector</span> <span class="o">=</span> <span class="n">X_train_count_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> 

<span class="c1">#train Naive Bayes model</span>
<span class="n">nb</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_count_vector</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1">#apply model to the grant titles</span>
<span class="n">X_test_count_vector</span> <span class="o">=</span> <span class="n">X_train_count_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_count_vector</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 5  3 10 ...  4  6  3]
</pre></div>
</div>
</div>
</div>
<p>One thing you’ve probably noticed is that this dataset does not explicitly have UNSDG classes associated with it. While we can do what we did in the previous exercise for this lab, it is often not the case that we have pre-labeled data. As such, one thing we can turn to is <em>unsupervised learning</em>. This was mentioned in the <a class="reference internal" href="sec4_classification_algos.html"><span class="std std-doc">section giving an overview on machine learning</span></a> and involves data that is not already labeled with the “correct” category.</p>
</section>
<section id="unsupervised-learning">
<h2><span class="section-number">14.11.2. </span>Unsupervised Learning<a class="headerlink" href="#unsupervised-learning" title="Link to this heading">#</a></h2>
<p>Two popular algorithms for unsupervised learning revolve around what is known as <em>clustering</em>. Clustering, similar to how the name sounds, puts data points into clusters such that there is high similarity within the cluster and low similarity between different clusters. The algorithms for this are a deterministic method called <span class="math notranslate nohighlight">\(k\)</span>-means, which puts each data point into a definitive cluster, and a probabilistic method called Gaussian Mixture Modeling, which assigns probabilities for each data point belonging in any cluster.</p>
<p><span class="math notranslate nohighlight">\(k\)</span>-means is described in more detail in the <a class="reference internal" href="../LinearAlgebra/KMeans/jnb2.html"><span class="std std-doc">chapter on linear algebra and optimization</span></a>. In practice, however, <span class="math notranslate nohighlight">\(k\)</span>-means clustering takes the following procedure:</p>
<ol class="arabic simple">
<li><p>Create <span class="math notranslate nohighlight">\(k\)</span> random points to serve as centroids; you choose the value of <span class="math notranslate nohighlight">\(k\)</span>. These will be the “centers” of each of our clusters.</p></li>
<li><p>Assign each existing data point to its closest centroid. This is typically done with Euclidean distance, or</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\text{dist} = \sqrt{(x_1-a_1)^2 + (x_2-a_2)^2 + ... + (x_j-a_j)^2}
\]</div>
<p>for data point <span class="math notranslate nohighlight">\(x\)</span> and centroid <span class="math notranslate nohighlight">\(a\)</span>, each with <span class="math notranslate nohighlight">\(j\)</span> features (columns in the dataset).</p>
<ol class="arabic simple" start="3">
<li><p>Measure the distance of each point from its assigned centroid and sum all these distances for all <span class="math notranslate nohighlight">\(n\)</span> points. Again, this is done with Euclidean distance.</p></li>
<li><p>Re-calculate the centroid of each cluster by taking the mean vector of all points in the cluster.</p></li>
<li><p>Repeat steps 2-4 until the total distance metric changes marginally between iterations, or until the centroids do not change position between iterations.</p></li>
</ol>
<p>Gaussian Mixture Modeling is similar to <span class="math notranslate nohighlight">\(k\)</span>-means, except it assigns probabilities for each point belonging to each cluster, assuming that each point follows a multivariate normal distribution from each cluster’s mean point. In practice, it is performed with the Expectation-Maximization (EM) algorithm. Its procedure works as follows:</p>
<ol class="arabic simple">
<li><p>Create <span class="math notranslate nohighlight">\(k\)</span> random points to serve as means, and assign each cluster a <span class="math notranslate nohighlight">\(j \times j\)</span> covariance matrix; this can be randomly set, but it is more common to use the identity matrix. These mean vectors and covariance matrices are the <em>mixture parameters</em>. We also need a prior probability to help with normalization in the next step, which is a single vector of length <span class="math notranslate nohighlight">\(k\)</span> detailing the prior probability of a point belonging in any one cluster. This vector is known as the <em>mixing proportions</em>.</p></li>
<li><p><em>Expectation Step</em>: Calculate the log-likelihood of the current data points given these randomly set parameters. This involves two main steps:</p></li>
</ol>
<ul class="simple">
<li><p>(a) Calculate the probability of each point belonging in each cluster using the multivariate normal probability density function. Following this, multiply these values by the respective probability found in the mixing proportions, then normalize these probabilities so that they sum to 1. These probabilities are stored in a matrix known as a <em>hidden matrix</em>.</p></li>
<li><p>(b) Take the cluster of highest probability for each point, then take the natural log of that probability. Perform that over all points, taking the sum of the natural logs.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p><em>Maximization Step</em>: Given the points assigned to each cluster of maximum likelihood, re-calculate the mean vector and covariance matrix for each cluster, as well as the mixing proportions.</p></li>
</ol>
<ul class="simple">
<li><p>To recalculate mixing proportions, take the cluster where each point has greatest probability to be in and “assign” the point that cluster. Then for each cluster, the new proportion is simply the number of points assigned to that cluster, divided by the total number of points.</p></li>
<li><p>To recalculate mean vectors, for each entry in each mean vector, take the corresponding feature in the data and take the dot product of it to each of the columns in the hidden matrix. Normalize the result based on the sums of the cluster, which gives us a single value for each k; we then do that <span class="math notranslate nohighlight">\(j\)</span> times to get the full matrix.</p></li>
<li><p>To recalculate covariance matrices, for each cluster, take the deviation of each point from the mean of the cluster and use these deviations to calculate a new covariance matrix. Then normalize the entries in this covariance matrix by the sums of the probabilities for that cluster.</p></li>
</ul>
<p>Clusters can be evaluated by a variety of metrics, including consulting domain experts or using Jaccard index. Evaluation of these clusters is beyond the scope of this lab.</p>
</section>
<section id="lab-exercises-part-2-unsupervised-learning">
<h2><span class="section-number">14.11.3. </span>Lab Exercises, Part 2: Unsupervised Learning<a class="headerlink" href="#lab-exercises-part-2-unsupervised-learning" title="Link to this heading">#</a></h2>
<ol class="arabic simple" start="9">
<li><p>Look at the documentation for <span class="math notranslate nohighlight">\(k\)</span>-means and the EM algorithm on <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> and use these with various <span class="math notranslate nohighlight">\(k\)</span> to cluster the grants. If you have a powerful computer, try <span class="math notranslate nohighlight">\(k = 17\)</span> to match the number of UN SDGs.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#answers for this will likely take the form of the following:</span>
<span class="c1">#for k-means:</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaled_data</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">count_vector_df_unigram</span><span class="p">)</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">scaled_data</span><span class="p">)</span>

<span class="c1">#for Gaussian Mixture Modeling with EM Algorithm:</span>
<span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
<span class="n">gm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">scaled_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="10">
<li><p>Look at the entries for one of the <span class="math notranslate nohighlight">\(k\)</span>-means clusters you made in the previous exercise. How similar are the entries to each other?</p></li>
</ol>
<p><em>Answers will vary due to the random nature of both clustering methods.</em></p>
<ol class="arabic simple" start="11">
<li><p>Compare the entries from the previous cluster you analyzed to a different cluster. How similar are the entries in the first cluster to the ones in the new cluster?</p></li>
</ol>
<p><em>Answers will vary both due to the random nature of clustering, as well as depending on the chosen clusters.</em></p>
<ol class="arabic simple" start="12">
<li><p>(Bonus) Implement <span class="math notranslate nohighlight">\(k\)</span>-means and the EM algorithm only using the <code class="docutils literal notranslate"><span class="pre">numpy</span></code> package - feel free to consult other resources for mathematical help. This exercise is not for the faint of heart but is advisable for those who want to improve their understanding of the mathematics underlying these methods!</p></li>
</ol>
<p><em>Implementations may vary. One example implementation is given below.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#For k-means:</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="k">def</span> <span class="nf">kmeans</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="c1">#so we can&#39;t have k less than 1, or there will be problems.</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Invalid k-value given; k must be at least 1&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>
    
    <span class="c1">#make a dictionary to hold the classes of all the items.</span>
    <span class="n">cluster_assignments</span> <span class="o">=</span> <span class="n">initial_new_cluster</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

    <span class="c1">#we also need something to hold our cluster evaluations</span>
    <span class="n">evals</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1">#set our initializations</span>
    <span class="n">inits</span> <span class="o">=</span> <span class="n">get_randinits</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

    <span class="c1">#main clustering process</span>
    <span class="n">clustered</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="c1">#a max iterations parameter for sanity check</span>
    <span class="n">maxRuns</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">numRuns</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="n">clustered</span> <span class="o">==</span> <span class="kc">False</span> <span class="ow">and</span> <span class="n">numRuns</span> <span class="o">&lt;</span> <span class="n">maxRuns</span><span class="p">:</span>
        <span class="n">prev_clusters</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">cluster_assignments</span><span class="p">)</span>
        <span class="n">cluster_assignments</span> <span class="o">=</span> <span class="n">initial_new_cluster</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">get_distances</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="n">inits</span><span class="p">)</span>
            <span class="n">minDist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>
            <span class="n">closest_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">dists</span> <span class="o">==</span> <span class="n">minDist</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">cluster_assignments</span><span class="p">[</span><span class="n">closest_cluster</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span>

        <span class="n">new_centers</span> <span class="o">=</span> <span class="n">get_new_centers</span><span class="p">(</span><span class="n">cluster_assignments</span><span class="p">,</span> <span class="n">inits</span><span class="p">)</span>
        <span class="c1">#check: are our centers the same?</span>
        <span class="c1">#if clusters_same(prev_clusters, cluster_assignments):</span>
        <span class="k">if</span> <span class="n">centroids_same</span><span class="p">(</span><span class="n">inits</span><span class="p">,</span> <span class="n">new_centers</span><span class="p">):</span>
            <span class="n">clustered</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inits</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">new_centers</span><span class="p">)</span>
            <span class="n">evals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eval_clusters</span><span class="p">(</span><span class="n">cluster_assignments</span><span class="p">,</span> <span class="n">inits</span><span class="p">))</span>
        <span class="n">numRuns</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">cluster_assignments</span><span class="p">,</span> <span class="n">evals</span>

<span class="k">def</span> <span class="nf">get_randinits</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="c1">#set min and max values per variable</span>
    <span class="n">minvals</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">maxvals</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1">#range over length of first vector</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
        <span class="n">current_min</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">current_max</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>

        <span class="c1">#now range over all rows:</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">current_min</span><span class="p">:</span>
                <span class="n">current_min</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">current_max</span><span class="p">:</span>
                <span class="n">current_max</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>

        <span class="n">minvals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_min</span><span class="p">)</span>
        <span class="n">maxvals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_max</span><span class="p">)</span>

    <span class="c1">#okay, now we have a list of the min/max values.</span>
    <span class="c1">#let&#39;s make random vectors with np.random.rand(k, len(minvals))</span>
    <span class="c1">#to each one, we&#39;ll multiply it by the range (min - max) and add the min.</span>
    <span class="n">inits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">minvals</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">minvals</span><span class="p">)):</span>
        <span class="n">current_range</span> <span class="o">=</span> <span class="n">maxvals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">minvals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">inits</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="n">current_range</span>
        <span class="n">inits</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">minvals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">inits</span>

<span class="c1">#two helper functions: get distances, and clusters same.</span>
<span class="k">def</span> <span class="nf">get_distances</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="n">inits</span><span class="p">):</span>
    <span class="n">dists</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">inits</span><span class="p">:</span>
        <span class="n">currentDist</span> <span class="o">=</span> <span class="n">get_dist</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
        <span class="n">dists</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">currentDist</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_dist</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)):</span>
        <span class="n">dist</span> <span class="o">+=</span> <span class="p">(</span><span class="n">entry</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">item</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">centroids_same</span><span class="p">(</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">):</span>
    <span class="n">same</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">c1</span> <span class="o">==</span> <span class="n">c2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">same</span>

<span class="k">def</span> <span class="nf">get_new_centers</span><span class="p">(</span><span class="n">clusters</span><span class="p">,</span> <span class="n">centers</span><span class="p">):</span>
    <span class="c1">#we&#39;ll get the data, and the number of clusters</span>
    <span class="n">newcenters</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">clusts</span> <span class="o">=</span> <span class="n">clusters</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">clusts</span><span class="p">:</span>
        <span class="n">current_clust</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">clusters</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
        <span class="c1">#for each cluster, we&#39;re going to average each variable</span>
        <span class="n">new_center</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_clust</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">newcenters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">centers</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">current_clust</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                <span class="n">new_center</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">current_clust</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]))</span>
            <span class="n">newcenters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_center</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">newcenters</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">eval_clusters</span><span class="p">(</span><span class="n">clusters</span><span class="p">,</span> <span class="n">centroids</span><span class="p">):</span>
    <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">centroids</span><span class="p">)):</span>
        <span class="n">current_clust</span> <span class="o">=</span> <span class="n">clusters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">current_clust</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="n">get_dist</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">centroids</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">score</span>

<span class="k">def</span> <span class="nf">initial_new_cluster</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="n">cluster_assignments</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">cluster_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">return</span> <span class="n">cluster_assignments</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#For GMM:</span>
<span class="k">def</span> <span class="nf">MultiVarNormal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    MultiVarNormal implements the PDF for a multivariate gaussian distribution</span>
<span class="sd">    (one sample at a time)</span>
<span class="sd">    Input:</span>
<span class="sd">        - x: (d,) numpy array</span>
<span class="sd">        - mean: (d,) numpy array; the mean vector</span>
<span class="sd">        - cov: (d,d) numpy array; the covariance matrix</span>
<span class="sd">    Output:</span>
<span class="sd">        prob - a scaler</span>
<span class="sd">    Hint:</span>
<span class="sd">        - Use np.linalg.det to compute determinant</span>
<span class="sd">        - Use np.linalg.pinv to invert a matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">pdf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1"># begin solution</span>
    <span class="c1">#added: another thing to keep in mind is that sometimes we get determinants very close to 0</span>
    <span class="c1">#this makes probabilities very large; much larger than 1</span>
    <span class="c1">#so we need to compute a pseudo-derivative if it is too small.</span>
    <span class="n">mydet</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
    <span class="c1">#if mydet &lt; 1e-12:</span>
        <span class="c1">#pseudo determinant through evals</span>
        <span class="c1">#evals, evecs = np.linalg.eig(cov)</span>
        <span class="c1">#mydet = np.product(evals[evals &gt; 1e-12])</span>
        <span class="c1">#d = np.linalg.matrix_rank(cov)</span>

    <span class="n">n1</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">**</span> <span class="n">d</span><span class="p">)</span> <span class="o">*</span> <span class="n">mydet</span><span class="p">)</span>
    <span class="n">n2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">cov</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)))))</span>
    <span class="n">pdf</span> <span class="o">=</span> <span class="n">n1</span><span class="o">*</span><span class="n">n2</span>
    <span class="c1"># end solution</span>
    <span class="k">return</span> <span class="n">pdf</span>

<span class="k">def</span> <span class="nf">UpdateMixProps</span><span class="p">(</span><span class="n">hidden_matrix</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the new mixing proportions given a hidden matrix</span>
<span class="sd">    Input:</span>
<span class="sd">        - hidden_matrix: (n, k) numpy array</span>
<span class="sd">    Output:</span>
<span class="sd">        - mix_props: (k,) numpy array</span>
<span class="sd">    Hint:</span>
<span class="sd">        - See equation in Lecture 10 pg 42</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span><span class="p">,</span><span class="n">k</span> <span class="o">=</span> <span class="n">hidden_matrix</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">mix_props</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="c1"># begin solution</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">current_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hidden_matrix</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span>
        <span class="n">mix_props</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_mean</span>

    <span class="c1"># end solution</span>
    <span class="k">return</span> <span class="n">mix_props</span>

<span class="k">def</span> <span class="nf">UpdateMeans</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">hidden_matrix</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Update means for gaussian distributions given the data and the hidden matrix</span>
<span class="sd">    Input:</span>
<span class="sd">        - X: (n, d) numpy array</span>
<span class="sd">        - hidden_matrix: (n, k) numpy array</span>
<span class="sd">    Output:</span>
<span class="sd">        - new_means: (k, d) numpy array</span>
<span class="sd">    Hint:</span>
<span class="sd">        - See equation in Lecture 10 pg 43</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span><span class="p">,</span><span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">hidden_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">new_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">k</span><span class="p">,</span><span class="n">d</span><span class="p">])</span>
    <span class="c1"># begin solution</span>
    <span class="c1">#so to think about this a little bit because for some reason I am not getting this:</span>
    <span class="c1">#we need to, for each entry in each mean vector, take the corresponding entry in the data (entry = feature)</span>
    <span class="c1">#then we need to dot product it by each of the columns in the hidden matrix</span>
    <span class="c1">#and then normalize based on the sums of the cluster, which gives us a single value for each k</span>
    <span class="c1">#then do that d times to get the full matrix.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">):</span> <span class="c1">#across the columns</span>
        <span class="n">current_subset</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="c1">#across the clusters</span>
            <span class="n">current_vals</span> <span class="o">=</span> <span class="n">hidden_matrix</span><span class="p">[:,</span><span class="n">c</span><span class="p">]</span>
            
            <span class="n">weighted_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">current_subset</span><span class="p">,</span> <span class="n">current_vals</span><span class="p">)</span>
            <span class="n">total_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">current_vals</span><span class="p">)</span>

            <span class="n">current_entry</span> <span class="o">=</span> <span class="n">weighted_val</span> <span class="o">/</span> <span class="n">total_prob</span>

            <span class="n">new_means</span><span class="p">[</span><span class="n">c</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_entry</span>
    <span class="c1"># end solution</span>
    <span class="k">return</span> <span class="n">new_means</span>

<span class="k">def</span> <span class="nf">UpdateCovars</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">hidden_matrix</span><span class="p">,</span> <span class="n">means</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Update covariance matrices for gaussian distributions given the data and the hidden matrix</span>
<span class="sd">    Input:</span>
<span class="sd">        - X: (n, d) numpy array</span>
<span class="sd">        - hidden_matrix: (n, k) numpy array</span>
<span class="sd">        - means: (k, d) numpy array; means for all distributions</span>
<span class="sd">    Output:</span>
<span class="sd">        - new_covs: (k, d, d) numpy array</span>
<span class="sd">    Hint:</span>
<span class="sd">        - See equation in Lecture 10 pg 43</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span><span class="p">,</span><span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">hidden_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">new_covs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">k</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">d</span><span class="p">])</span>
    <span class="c1"># begin solution</span>
    <span class="c1">#to think about this:</span>
    <span class="c1">#first we want to range through each cluster</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="c1">#we want to get the sum of probabilities for this cluster</span>
        <span class="n">current_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hidden_matrix</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span>

        <span class="c1">#next we want to range through each data point</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="c1">#take the deviation from the mean of the cluster</span>
            <span class="n">current_diff</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            
            <span class="c1">#take the probability for this data point from this cluster</span>
            <span class="n">current_prob</span> <span class="o">=</span> <span class="n">hidden_matrix</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>

            <span class="c1">#need to get the matrix - np.matmul does not work here</span>
            <span class="c1">#so we need to brute force this</span>
            <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
                    <span class="n">current_cov</span> <span class="o">=</span> <span class="n">current_diff</span><span class="p">[</span><span class="n">a</span><span class="p">]</span> <span class="o">*</span> <span class="n">current_diff</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">*</span> <span class="n">current_prob</span>
                    <span class="n">new_covs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">]</span> <span class="o">+=</span> <span class="n">current_cov</span>

        <span class="c1">#then normalize the entries</span>
        <span class="n">new_covs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_covs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">current_sum</span>
    <span class="c1"># end solution</span>
    <span class="k">return</span> <span class="n">new_covs</span>

<span class="k">def</span> <span class="nf">HiddenMatrix</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">covs</span><span class="p">,</span> <span class="n">mix_props</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the hidden matrix for the data.</span>
<span class="sd">    This function should also compute the log likelihood</span>
<span class="sd">    Input:</span>
<span class="sd">        - X: (n, d) numpy array</span>
<span class="sd">        - means: (k, d) numpy array; the mean vectors</span>
<span class="sd">        - new_covs: (k, d, d) numpy array; the covariance matrices</span>
<span class="sd">        - mix_props: (k,) numpy array; the mixing proportions</span>
<span class="sd">    Output:</span>
<span class="sd">        - hidden_matrix: (n, k) numpy array</span>
<span class="sd">        - ll: scalar; the log likelihood</span>
<span class="sd">    Hint:</span>
<span class="sd">        - Construct an intermediate matrix t of shape (n, k).</span>
<span class="sd">            t[i,j] = P(X_i | c = j)P(c = j), for i=1,...,n, j=1,...,k</span>
<span class="sd">            This matrix can be used to calculate the loglikelihood and the hidden matrix.</span>
<span class="sd">        - Each row of the hidden matrix sums to 1</span>
<span class="sd">        - hidden_matrix[i,j] = P(X_i | c = j)P(c = j) / (Sum_{l=1}^{k}(P(X_i | c = l)P(c = l))),</span>
<span class="sd">            for i=1,...,n, j=1,...,k</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span><span class="p">,</span><span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">hidden_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="p">])</span>
    <span class="n">ll</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="p">])</span> <span class="c1"># intermediate matrix</span>
    
    <span class="c1"># begin solution</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span> <span class="c1">#across the rows</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="c1">#across the clusters</span>
            <span class="n">current_mean</span> <span class="o">=</span> <span class="n">means</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>
            <span class="n">current_cov</span> <span class="o">=</span> <span class="n">covs</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>
            <span class="n">current_mix</span> <span class="o">=</span> <span class="n">mix_props</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>

            <span class="n">current_prob</span> <span class="o">=</span> <span class="n">MultiVarNormal</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">current_mean</span><span class="p">,</span> <span class="n">current_cov</span><span class="p">)</span>
            <span class="c1">#current_prob = stats.multivariate_normal.pdf(X[i, :], current_mean, current_cov)</span>
            <span class="n">current_entry</span> <span class="o">=</span> <span class="n">current_prob</span> <span class="o">*</span> <span class="n">current_mix</span>

            <span class="n">hidden_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_entry</span>

    <span class="c1">#we have the intermediate matrix, we now need to normalize so these entries sum to 1</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">current_total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hidden_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="c1">#across the columns, which is the clusters for hidden matrix</span>
            <span class="n">current_val</span> <span class="o">=</span> <span class="n">hidden_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">/</span> <span class="n">current_total</span>
            <span class="n">hidden_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_val</span>

    <span class="c1">#now to take the log likelihood via the matrix</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="c1">#we want the log-likelihood of the biggest value</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">hidden_matrix</span><span class="p">[</span><span class="n">a</span><span class="p">,:])</span>
        <span class="n">ll</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">hidden_matrix</span><span class="p">[</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">])</span>

    <span class="c1"># end solution</span>
    <span class="k">return</span> <span class="n">hidden_matrix</span><span class="p">,</span><span class="n">ll</span>

<span class="k">def</span> <span class="nf">GMM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">init_means</span><span class="p">,</span> <span class="n">init_covs</span><span class="p">,</span> <span class="n">init_mix_props</span><span class="p">,</span> <span class="n">thres</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs the GMM algorithm</span>
<span class="sd">    Input:</span>
<span class="sd">        - X: (n, d) numpy array</span>
<span class="sd">        - init_means: (k,d) numpy array; the initial means</span>
<span class="sd">        - init_covs: (k,d,d) numpy arry; the initial covariance matrices</span>
<span class="sd">        - init_mix_props: the initial mixing proportions</span>
<span class="sd">    Output:</span>
<span class="sd">        - clusters: (n,) numpy array; the cluster assignment for each sample</span>
<span class="sd">        - hidden_matrix: (n, k) numpy array</span>
<span class="sd">        - ll_list: the log likelihood at all iterations</span>
<span class="sd">    Hint:</span>
<span class="sd">        - Use all above functions</span>
<span class="sd">        - Stoping condition: the difference between your ll from the current iteration</span>
<span class="sd">            and the last iteration is below your threshold</span>
<span class="sd">        - You can set maximum iteration as 1,000 to avoid infinite loop</span>
<span class="sd">        - Remember to check if your algorithm has converged</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span><span class="p">,</span><span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">init_means</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">ll_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># begin solution</span>
    <span class="n">threshold_met</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">current_iter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">current_means</span> <span class="o">=</span> <span class="n">init_means</span>
    <span class="n">current_covs</span> <span class="o">=</span> <span class="n">init_covs</span>
    <span class="n">current_mix</span> <span class="o">=</span> <span class="n">init_mix_props</span>
    <span class="k">while</span> <span class="n">threshold_met</span> <span class="o">!=</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1">#first: get the hidden matrix and log-likelihood</span>
        <span class="n">current_hidden</span><span class="p">,</span> <span class="n">current_ll</span> <span class="o">=</span> <span class="n">HiddenMatrix</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">current_means</span><span class="p">,</span> <span class="n">current_covs</span><span class="p">,</span> <span class="n">current_mix</span><span class="p">)</span>
        <span class="n">ll_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_ll</span><span class="p">)</span>

        <span class="c1">#second: update all parameters</span>
        <span class="n">current_means</span> <span class="o">=</span> <span class="n">UpdateMeans</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">current_hidden</span><span class="p">)</span>
        <span class="n">current_covs</span> <span class="o">=</span> <span class="n">UpdateCovars</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">current_hidden</span><span class="p">,</span> <span class="n">current_means</span><span class="p">)</span>
        <span class="n">current_mix</span> <span class="o">=</span> <span class="n">UpdateMixProps</span><span class="p">(</span><span class="n">current_hidden</span><span class="p">)</span>

        <span class="c1">#third: check if our threshold is met</span>
        <span class="c1">#or if we have only run one time.</span>
        <span class="k">if</span> <span class="n">current_iter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">current_iter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">ll_list</span><span class="p">[</span><span class="n">current_iter</span><span class="p">]</span> <span class="o">-</span> <span class="n">ll_list</span><span class="p">[</span><span class="n">current_iter</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">thres</span><span class="p">:</span>
            <span class="n">threshold_met</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">current_iter</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1">#now we need to put each point into a cluster</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">largest_prob_cluster</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">current_hidden</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:])</span>
        <span class="n">clusters</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">largest_prob_cluster</span>
    <span class="c1"># end solution</span>
    <span class="k">return</span> <span class="n">clusters</span><span class="p">,</span><span class="n">current_hidden</span><span class="p">,</span><span class="n">ll_list</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="lab-exercises-part-3-similarity">
<h2><span class="section-number">14.11.4. </span>Lab Exercises, Part 3: Similarity<a class="headerlink" href="#lab-exercises-part-3-similarity" title="Link to this heading">#</a></h2>
<ol class="arabic simple" start="13">
<li><p>Construct a heatmap for 40 of the grants in the dataset.</p></li>
</ol>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/px/b7vc3nh913zb_m0x36ncftj00000gn/T/ipykernel_68678/3899229267.py:6: DtypeWarning: Columns (33,36,37) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(&quot;GrantsDBExtract20240625v2.csv&quot;)[:10000]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>

<span class="c1"># change this to your own embedding directory</span>
<span class="n">embedding_dir</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="c1"># load the embedding</span>
<span class="n">embed</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">embedding_dir</span> <span class="o">+</span> <span class="s2">&quot;universal-sentence-encoder_4&quot;</span><span class="p">)</span>

<span class="n">df</span><span class="p">[</span><span class="s2">&quot;embedding&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">embed</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">OpportunityTitle</span><span class="p">))</span>

<span class="c1">#make heatmap of similarities</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">embedding</span><span class="p">[:</span><span class="mi">40</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> 
                              <span class="n">df</span><span class="o">.</span><span class="n">embedding</span><span class="p">[:</span><span class="mi">40</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-07-15 21:10:45.922395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;inputs&#39; with dtype string
	 [[{{node inputs}}]]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: &gt;
</pre></div>
</div>
<img alt="../../_images/5992738bd95e72352e735f2677360141198731c982028002f735dad0ad0ef0a8.png" src="../../_images/5992738bd95e72352e735f2677360141198731c982028002f735dad0ad0ef0a8.png" />
</div>
</div>
<ol class="arabic simple" start="14">
<li><p>Isolate twenty of the entries, then write a function that will take one of these twenty entries and an integer <span class="math notranslate nohighlight">\(k\)</span> as an input; the function will return the <span class="math notranslate nohighlight">\(k\)</span> most similar entries in the rest of the dataset.</p></li>
</ol>
<p><em>The function and its setup are given as follows:</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_set</span> <span class="o">=</span> <span class="n">df</span><span class="p">[:</span><span class="mi">20</span><span class="p">]</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">20</span><span class="p">:]</span>

<span class="k">def</span> <span class="nf">get_most_similar</span><span class="p">(</span><span class="n">text_df</span><span class="p">,</span> <span class="n">point</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">point</span><span class="o">.</span><span class="n">OpportunityTitle</span>
    <span class="n">sentence_sim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">text_df</span><span class="o">.</span><span class="n">embedding</span><span class="p">),</span> <span class="n">embed</span><span class="p">([</span><span class="n">sentence</span><span class="p">]))</span>
    <span class="n">val</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">sentence_sim</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">n</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">text_df</span><span class="p">[</span><span class="n">sentence_sim</span> <span class="o">&gt;</span> <span class="n">val</span><span class="p">]</span><span class="o">.</span><span class="n">OpportunityTitle</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Grants most similar to grant&quot;</span><span class="p">,</span> <span class="n">test_set</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">OpportunityTitle</span><span class="p">)</span>
<span class="n">get_most_similar</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grants most similar to grant Establishment of the Edmund S. Muskie Graduate Internship Program
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>427     Internship Training Program Interior Museum Pr...
3015                  Career Discovery Internship Program
7994                Mosaics in Science Internship Program
7995                Mosaics in Science Internship Program
8964                      Buiness Plan Internship Program
Name: OpportunityTitle, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="generative-ai-and-language-models">
<h2><span class="section-number">14.11.5. </span>Generative AI and Language Models<a class="headerlink" href="#generative-ai-and-language-models" title="Link to this heading">#</a></h2>
<p>With the rise of generative AI and large language models like the GPT-system of models developed by OpenAI, it is easier than ever to give a model a string of text and have it classify these texts into predicted UN SDGs.</p>
<p>So how exactly do these models work? The exact mathematical theory behind these models is highly complex as they build on years of research on AI, natural language processing, and machine learning. We mention generative text models briefly in <a class="reference internal" href="sec2_transform_features.html"><span class="std std-doc">a previous section</span></a>, and state that these models are similar to probabilistic language models but are <em>generative</em> in the sense that they will generate the next word in the sequence based on a highly complex model.</p>
<p>We won’t have you recreate any generative AI programs here. Instead, we will provide a quick guide through best practices to use them in the context of text classification.</p>
<p>The guiding principle is to <strong>be as specific as possible and narrow the desired task as much as you can.</strong> Expect that you will sometimes get incorrect results, or ones that do not align with the task you intended. As you go, iterate and fine-tune the prompts so that they become more specific.</p>
<p>Additionally, some advanced prompting techniques exist, including few-shot prompting and chain-of-thought prompting, which provides some examples for the LLM or guides the LLM through a few reasoning steps, respectively.</p>
</section>
<section id="lab-exercises-part-4-generative-ai-and-language-models">
<h2><span class="section-number">14.11.6. </span>Lab Exercises, Part 4: Generative AI and Language Models<a class="headerlink" href="#lab-exercises-part-4-generative-ai-and-language-models" title="Link to this heading">#</a></h2>
<ol class="arabic simple" start="15">
<li><p>Use a LLM available online, such as ChatGPT, and ask it what UNSDGs it predicts some of the grants to fall under using simple question asking. For example, “For a grant with the title __________, what UNSDG aligns best with the grant?” Do the classifications make sense?</p></li>
</ol>
<p><em>Answers may vary but should make sense if an advanced LLM is used.</em></p>
<ol class="arabic simple" start="16">
<li><p>Use few-shot prompting to classify some other grants. Utilize your own previous classification models (or your own classifications) to provide shots to the prompt. For example, “The grant titled _____________ falls under UN SDG _____. The grant titled __________ falls under which UNSDG?” Compare the classifications from this step with the classifications from the previous step.</p></li>
</ol>
<p><em>Answers may vary but should make sense if an advanced LLM is used. Prompts should also follow the format specified in this question.</em></p>
<ol class="arabic simple" start="17">
<li><p>(Bonus) Check out the following additional resources for more details on LLM prompting. Code along with the code provided on the pages and provide your resulting notebooks to answer this question. Extend the principles found in resources to some of these grant titles as well.</p></li>
</ol>
<ul class="simple">
<li><p><a class="reference external" href="https://cookbook.openai.com/examples/multiclass_classification_for_transactions">https://cookbook.openai.com/examples/multiclass_classification_for_transactions</a>: a resource from OpenAI, utilizing the capabilities of some of their own models, to classify text documents</p></li>
<li><p><a class="reference external" href="https://huggingface.co/docs/transformers/main/tasks/prompting">https://huggingface.co/docs/transformers/main/tasks/prompting</a>: a resource from HuggingFace, a package we used in this section, that talks more about general LLM prompting.</p></li>
</ul>
<p><em>Answers should follow the code examples given on the websites.</em></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Advanced/AdvDataAnalysis"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="nlp_lab.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">14.10. </span>JNB Lab: United States Grant Data</p>
      </div>
    </a>
    <a class="right-next"
       href="../../ComplexSystems.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">15. </span>COMPLEX SYSTEMS - Wheaton College Team</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-exercises-part-1-supervised-learning-and-vectorizations">14.11.1. Lab Exercises, Part 1: Supervised Learning and Vectorizations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unsupervised-learning">14.11.2. Unsupervised Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-exercises-part-2-unsupervised-learning">14.11.3. Lab Exercises, Part 2: Unsupervised Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-exercises-part-3-similarity">14.11.4. Lab Exercises, Part 3: Similarity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-ai-and-language-models">14.11.5. Generative AI and Language Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-exercises-part-4-generative-ai-and-language-models">14.11.6. Lab Exercises, Part 4: Generative AI and Language Models</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Paul Isihara, Claire Wagner, Peter Jantsch, and Thomas VanDrunen, Editors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
  <a rel='license' href='http://creativecommons.org/licenses/by/4.0/'><img alt='Creative Commons License' width=88 style='border-width:0' src='https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by.png'/></a>
  Except where otherwise noted, this work is licensed under a <a rel='license' href='http://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 International License</a>.
</p>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>