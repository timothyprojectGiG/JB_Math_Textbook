{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163ac330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# Always run this cell first!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import scipy\n",
    "import statsmodels.api # appear to need to import the api as well as the library itself for the interpreter to find the modules\n",
    "import statsmodels as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline\n",
    "plotly.offline.init_notebook_mode(connected=True) # make plotly work with Jupyter Notebook using CDN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea9db9",
   "metadata": {},
   "source": [
    "# Foundations of Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658b43e",
   "metadata": {},
   "source": [
    "This chapter is all about how to use statistics to make decision from data, a process known as statistical inference. Because data is usually incomplete and has a lot of variability, this decision making process inherently contains a lot of uncertainty. But the difficulty shouldn't deter us! The statistical decision-making process is based on a robust theory of probability, and one of the easiest ways to illustrate this theory is using computation. \n",
    "\n",
    "In this section we take a look at one of the main probability results that allows us to do statistical inference: the Central Limit Theorem. We'll then show how the Central Limit Theorem leads us to the first tool of statistical inference, the confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607ba0f",
   "metadata": {},
   "source": [
    "## Sampling and the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad24cf6",
   "metadata": {},
   "source": [
    "To get us thinking about statistical decision-making, let's imagine a hypothetical scenario where we are an agent for a football player (that's *soccer* to Americans). As an agent, we want to negotiate a good deal for our client, who plays in the English Premier League. To do this we might need to first try to estimate the average salary for all players in the league.\n",
    "\n",
    "Unlike a real-world statistical estimate, in this scenario we have access to the entire *population* of player salaries for the 2022-23 Premier League season. This data comes from [FBref](https://fbref.com/en/comps/9/wages/Premier-League-Wages) and is in units of pounds (£, GBP) per week.\n",
    "\n",
    "Here we will read in the data, which is in the file `EPL_wages_22_23.csv`, and display the first 10 rows. These correspond to the 10 highest paid players---you may recognize some of the names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcbb09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.read_csv(\"EPL_wages_22_23.csv\").drop(columns=[\"Rk\",\"Notes\", \"Player-additional\",\"Annual Wages\"])\n",
    "salaries[\"Weekly Wages (GBP)\"] = salaries[\"Weekly Wages\"].str.extract('(\\d+)').astype(int)\n",
    "salaries.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74106e95",
   "metadata": {},
   "source": [
    "One of the key ideas in statistics is that even if the distribution of the population (in this case, footballers' weekly salaries) is not normal, the distribution of the average salary of a large number of *randomly selected* footballers *does* have an (approximately) normal distribution. Hence, even though any estimation we make from a sample contains some uncertainty, we can quantify that uncertainty and make the best decision possible.\n",
    "\n",
    "*Note:* Of course, there are probably a lot more helpful things to calculate than simply the average player salary. For instance, we could look at salaries of players with similar statistics. Take a look at the section on linear algebra and clustering. **(add link here later)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857cb48",
   "metadata": {},
   "source": [
    "We begin by taking a look at the population of all player salaries. Note that this distribution is highly skewed, and far from being normal. In fact, the distribution of player salaries is modeled fairly well with an exponential distribution! Below, we calculate the mean and standard deviation of the weekly wages from this dataset, and compare the histogram of weekly wages to the normal distribution with the same mean and standard deviation as well as the exponential distribution with the same mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a459f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean = salaries[\"Weekly Wages (GBP)\"].mean()\n",
    "pop_sd = salaries[\"Weekly Wages (GBP)\"].std()\n",
    "print(f\"Population mean is {pop_mean:.3f}, standard deviation is {pop_sd:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155a8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_wages = salaries['Weekly Wages (GBP)']\n",
    "\n",
    "# use default seaborn palette\n",
    "palette = iter(sns.color_palette())\n",
    "\n",
    "# plot histogram\n",
    "axis = sns.histplot(\n",
    "    data = weekly_wages,\n",
    "    stat = 'density',\n",
    "    color = next(palette), # use next color in palette\n",
    "    alpha = 0.4,\n",
    "    label = 'histogram of weekly wages'\n",
    ")\n",
    "\n",
    "# plot exponential distribution\n",
    "x = np.linspace(0, max(weekly_wages), 100)\n",
    "axis.plot(\n",
    "    x,\n",
    "    scipy.stats.expon.pdf(x, scale=np.mean(weekly_wages)),\n",
    "    color = next(palette), # use next color in palette\n",
    "    linewidth = 3,\n",
    "    label = 'exponential distribution'\n",
    ")\n",
    "\n",
    "# plot normal distribution\n",
    "x = np.linspace(-100000, max(weekly_wages), 100)\n",
    "axis.plot(\n",
    "    x,\n",
    "    scipy.stats.norm.pdf(x, loc=np.mean(weekly_wages), scale=np.std(weekly_wages)),\n",
    "    color = next(palette), # use next color in palette\n",
    "    linewidth = 3,\n",
    "    label = 'normal distribution'\n",
    ")\n",
    "\n",
    "axis.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "axis.set_title(\"Distribution of Weekly Wages\")\n",
    "axis.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7bd110",
   "metadata": {},
   "source": [
    "In our hypothetical scenario, let's imagine that we didn't have access to *all* of the data, but only knew the salaries for 35 random players. We could take the average salary of those 35 players, but would it be close to the real average salary of *all* the players? \n",
    "\n",
    "The following code will take a random sample of 35 players, and compute the (sample) average of the salaries of those players. Is it close to the actual salary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79efb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sample = salaries.sample(n=35)\n",
    "\n",
    "sample_mean = my_sample[\"Weekly Wages (GBP)\"].mean()\n",
    "sample_sd = my_sample[\"Weekly Wages (GBP)\"].std()\n",
    "\n",
    "print(f\"Sample mean is {sample_mean:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a2bb6",
   "metadata": {},
   "source": [
    "It's important to note that this sample mean is just one possible value. If we had taken a different random sample of 35 players, we would get a different sample average. You can see this for yourself if you run the code several times. We thus understand the sample mean as a random variable.\n",
    "\n",
    "As an example, if we randomly selected highly-paid players such as Cristiano Ronaldo, we would expect our sample average to be higher than the population average. If we randomly selected a lot of young players or reserves, we would expect our sample average to be lower. But how much lower or higher is possible? How much lower or higher should we expect? We can answer this question by understanding sampling distributions. In other words, if the sample mean is a random variable, what is its distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c783f37",
   "metadata": {},
   "source": [
    "Because we have access to the entire population of data, we can explore this idea through simulation. Instead of taking just one sample mean from a sample of size 35, we can take many of them and look at the possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe7a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the means of 1000 random samples of size 35\n",
    "many_sample_means = [salaries.sample(n=35)[\"Weekly Wages (GBP)\"].mean() for i in range(1000)]\n",
    "\n",
    "# plot histogram of many_sample_means\n",
    "axis = sns.histplot(\n",
    "    data = many_sample_means,\n",
    "    stat = 'density',\n",
    "    alpha = 0.6,\n",
    ")\n",
    "axis.ticklabel_format(style='plain', axis='y')\n",
    "axis.set_xlabel(\"Average Weekly Wages (GBP)\")\n",
    "axis.set_title(\"Histogram of Many Sample Means\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc8c93",
   "metadata": {},
   "source": [
    "Now let's compare this to the theory. What does the Central Limit Theorem tell us? \n",
    "\n",
    "If the sample size is \"large enough\", then the sample mean, considered as a random variable, is approximately normally distributed with the same mean as the population and with standard deviation equal to the population standard deviation divided by the sample size. In mathematical language,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\overline{X} \\sim N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\overline{X}$ is the sample mean, $\\mu$ is the population mean, $\\sigma$ is the population standard deviation, and $n$ is the sample size.\n",
    "\n",
    "In our case, $n = 35$, and the population mean and standard deviation were calculated above. Let's replot our histogram of `many_sample_means`, along with the normal distribution with the same mean and standard deviation, and see how it matches up with the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d192bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same histogram as above, with normal distribution overlay\n",
    "\n",
    "# use default seaborn palette\n",
    "palette = iter(sns.color_palette())\n",
    "\n",
    "# plot histogram\n",
    "histcolor = next(palette) # use next color in palette\n",
    "axis = sns.histplot(\n",
    "    data = many_sample_means,\n",
    "    stat = 'density',\n",
    "    color = histcolor,\n",
    "    alpha = 0.6,\n",
    "    label = 'histogram of\\nmany_sample_means'\n",
    ")\n",
    "\n",
    "# plot normal distribution\n",
    "x = np.linspace(min(many_sample_means), max(many_sample_means), 100)\n",
    "axis.plot(\n",
    "    x,\n",
    "    scipy.stats.norm.pdf(x, loc=np.mean(many_sample_means), scale=np.std(many_sample_means)),\n",
    "    color = next(palette), # use next color in palette\n",
    "    linewidth = 4,\n",
    "    label = 'normal distribution'\n",
    ")\n",
    "\n",
    "axis.ticklabel_format(style='plain', axis='y')\n",
    "axis.set_xlabel(\"Average Weekly Wages (GBP)\")\n",
    "axis.set_title(\"Distribution of Many Sample Means\")\n",
    "axis.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ea13e6",
   "metadata": {},
   "source": [
    "We now see that even though the average weekly salary of 35 players is variable, and changes based on which 35 players we get, overall we have a good idea of which values we're likely to get!\n",
    "\n",
    "All of this depends on the sample size being \"large enough\", which leaves us with a big question: how large is large enough?\n",
    "\n",
    "You can play around with the interactive widget below to try different sample sizes and see how well the theoretical normal distribution matches up with the sampling distribution. Given a sample size, the widget plots the average of 10000 random samples of that size from the salary data, overlaid with the normal distribution with the same mean and standard deviation.\n",
    "\n",
    "Drag the slider to select different sample sizes, and click the labels in the legend to hide or show different parts of the graph. Notice how the histogram of the averages fits the normal distribution more closely as the sample size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eedf171",
   "metadata": {
    "scrolled": false,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the average of reps samples from data with the given sample size and replacement policy\n",
    "def get_sample_avg(data, size, reps, replace=False):\n",
    "    return [np.mean(data.sample(size, replace=replace).to_numpy()) for i in range(reps)]\n",
    "\n",
    "# Define sample sizes and number of repetitions for sampling\n",
    "sample_sizes = np.arange(5, 45, 5)\n",
    "n = len(sample_sizes)\n",
    "reps = 10000\n",
    "\n",
    "# Use default seaborn palette (reference: https://josephlemaitre.com/2022/06/use-a-seaborn-color-palette-for-plotly-figures/)\n",
    "plotly_palette = iter([f\"rgb({c[0]*256}, {c[1]*256}, {c[2]*256})\" for c in sns.color_palette()])\n",
    "histcolor = next(plotly_palette)\n",
    "normcolor = next(plotly_palette)\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Set consistent limits for axes in all traces\n",
    "xlim = (12000, 200000)\n",
    "ylim = (0, 4.5e-05)\n",
    "\n",
    "# Define which sample size will be initially visible\n",
    "# (note that this is the index of the sample size)\n",
    "initial_sample_size_index = 0\n",
    "\n",
    "# Get averages for all possible sample sizes\n",
    "# averages[i] is the average of reps samples of size sample_sizes[i] (with replacement)\n",
    "averages = [get_sample_avg(salaries[\"Weekly Wages (GBP)\"], size, reps, replace=True) for size in sample_sizes]\n",
    "\n",
    "# Add histogram traces\n",
    "# (the histogram for averages[i] is plotted as the ith trace, fig.data[i])\n",
    "for i, avg in enumerate(averages):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            # initially, only the histogram for initial_sample_size should be visible\n",
    "            visible = True if i == initial_sample_size_index else False,\n",
    "            name = \"histogram<br>of averages\", # label for legend\n",
    "            x = avg,\n",
    "            marker = { \"color\": histcolor },\n",
    "            hoverinfo = \"x+y\",\n",
    "            histnorm = \"probability density\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add normal pdf traces\n",
    "# (the normal pdf for averages[i] is plotted as the (i+n)th trace, fig.data[i+n])\n",
    "x = np.linspace(*xlim, 100)\n",
    "for i, avg in enumerate(averages):\n",
    "    # determine x-axis limits\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            # initially, only the normal pdf for initial_sample_size should be visible\n",
    "            visible = True if i == initial_sample_size_index else False,\n",
    "            line = { \"width\": 4 },\n",
    "            marker = { \"color\": normcolor },\n",
    "            name = \"normal<br>distribution\", # label for legend\n",
    "            hoverinfo = \"x+y\",\n",
    "            x = x,\n",
    "            y = scipy.stats.norm.pdf(x, np.mean(avg), np.std(avg))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "get_title = lambda i: f\"Averages of {reps} Random Samples of Size {sample_sizes[i]}\"\n",
    "\n",
    "# Create steps for the slider to select sample size\n",
    "steps = []\n",
    "for i in range(n):\n",
    "    steps.append({\n",
    "        \"method\": \"update\",\n",
    "        \"args\": [ # arguments to pass to the update method\n",
    "            # update visibility so only the histogram and normal pdf for this sample size are visible\n",
    "            { \"visible\": [True if (j == i or j-n == i) else False for j in range(len(fig.data))] },\n",
    "            # update the title to reflect the change to the sample size\n",
    "            { \"title\": get_title(i) }\n",
    "        ],\n",
    "        \"label\": str(sample_sizes[i]),\n",
    "    })\n",
    "\n",
    "# Create a slider using these steps and add it to fig\n",
    "fig.layout.sliders = [{\n",
    "    \"active\": initial_sample_size_index,\n",
    "    \"currentvalue\": { \"prefix\": \"Sample Size: \" },\n",
    "    \"pad\": {\"t\": 50},\n",
    "    \"steps\": steps,\n",
    "}]\n",
    "\n",
    "# Set layout settings\n",
    "fig.update_layout(\n",
    "    title = {\n",
    "        \"x\": 0.5,\n",
    "        \"text\": get_title(initial_sample_size_index)\n",
    "    },\n",
    "    xaxis = {\n",
    "        \"title\": \"Average Weekly Wages (GBP)\",\n",
    "        \"range\": xlim,\n",
    "        \"constrain\": \"domain\",\n",
    "    },\n",
    "    yaxis = {\n",
    "        \"title\": \"Probability Density\",\n",
    "        \"tickformat\": \".2\",\n",
    "        \"range\": ylim,\n",
    "        \"constrain\": \"domain\",\n",
    "    },\n",
    "    paper_bgcolor = \"LightSteelBlue\"\n",
    ")\n",
    "\n",
    "# Display figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68837c1",
   "metadata": {},
   "source": [
    "Statisticians will usually say that a sample size of 30 is large enough. Based on the widget above, would you agree with that? Do the distributions look approximately normal at that sample size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8c2f4",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd3e8e",
   "metadata": {},
   "source": [
    "In real life, the situation is much different. We will typically only have one sample, and hence one sample mean. We now know that if our sample size $n$ is large enough, we are likely to be close to the true population mean. But how close are we? And can we quantify what \"likely\" means in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719b042",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) tells us where $\\overline X$ is likely to be in relation to $\\mu$. Since $\\displaystyle \\overline{X} \\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}})$, we know that 95% of the time, $\\overline X$ will fall within a distance of about 2 standard deviations from $\\mu$ (technically, the distance is more like 1.96). In other words, 95% of the area under the density function is between $\\displaystyle \\mu-1.96 \\frac{\\sigma}{\\sqrt{n}}$ and $\\displaystyle \\mu + 1.96  \\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "The plot below illustrates what 95% of the area under the standard normal density function looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0902fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot\n",
    "fig, ax = plt.subplots(figsize=(8.5,4.5))\n",
    "\n",
    "# use default seaborn palette\n",
    "palette = iter(sns.color_palette())\n",
    "\n",
    "# plot standard normal pdf\n",
    "x = np.linspace(-3.5, 3.5, 100)\n",
    "y = scipy.stats.norm.pdf(x, 0, 1)\n",
    "ax.plot(x, y, color=next(palette), linewidth=2, label='pdf')\n",
    "\n",
    "# set lower y-axis limit to 0\n",
    "ax.set_ylim(0, ax.get_ylim()[1])\n",
    "\n",
    "# plot mean and standard deviation\n",
    "ax.vlines(x=0, ymin=0, ymax=scipy.stats.norm.pdf(0), linestyle='dashed', color='grey', label='$\\mu=0, \\sigma=1$')\n",
    "ax.vlines(x=-1, ymin=0, ymax=scipy.stats.norm.pdf(-1), linestyle='dashed', color='grey')\n",
    "ax.vlines(x=1, ymin=0, ymax=scipy.stats.norm.pdf(1), linestyle='dashed', color='grey')\n",
    "\n",
    "# plot and annotate x = ±1.96\n",
    "linecolor = next(palette)\n",
    "ax.axvline(-1.96, linestyle='dashed', color=linecolor, label='$x = \\pm1.96$')\n",
    "ax.axvline(1.96, linestyle='dashed', color=linecolor)\n",
    "half_ylim = sum(ax.get_ylim())/2 # coordinate at middle of y-axis\n",
    "ax.annotate(\n",
    "    'x = –1.96',\n",
    "    xy = (-1.96, half_ylim),\n",
    "    xytext = (-25.5, 0),\n",
    "    textcoords = 'offset pixels',\n",
    "    fontsize = 'medium'\n",
    ")\n",
    "ax.annotate(\n",
    "    'x = 1.96',\n",
    "    xy = (1.96, half_ylim),\n",
    "    xytext = (-25.5, 0),\n",
    "    textcoords = 'offset pixels',\n",
    "    fontsize = 'medium'\n",
    ")\n",
    "\n",
    "# fill between x = ±1.96\n",
    "ax.fill_between(x, y, where = (x > -1.96) & (x < 1.96), alpha=0.4, label='95% of area')\n",
    "\n",
    "# set up legend, y-axis label, and title\n",
    "ax.legend()\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Standard Normal Distribution ($\\mu=0, \\sigma=1$)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153003f9",
   "metadata": {},
   "source": [
    "Now we know where $\\overline X$ is likely to fall in relation to $\\mu$. We can express what we see in the graph as a probability:\n",
    "\\begin{equation}\n",
    "    P\\left(\\mu-1.96 \\frac{\\sigma}{\\sqrt{n}} \\le \\overline X \\le \\mu + 1.96  \\frac{\\sigma}{\\sqrt{n}}\\right) = .95.\n",
    "\\end{equation}\n",
    "With a little bit of algebraic manipulation, we can write this as an interval for $\\mu$:\n",
    "\\begin{equation}\n",
    "    P\\left(\\overline{X}-1.96 \\frac{\\sigma}{\\sqrt{n}} \\le \\mu \\le \\overline{X} + 1.96  \\frac{\\sigma}{\\sqrt{n}}\\right) = .95.\n",
    "\\end{equation}\n",
    "In the real world, we'll have a value of $\\overline{X}$, and we want to know where $\\mu$ is. This second interval gives us exactly this! Look at what's on the upper and lower side of the interval: (almost) all things we can calculate from the data, like $\\overline X$ and $n$ (we'll discuss how to handle the $\\sigma$ in a moment). This gives an interval for $\\mu$, the population mean that we can't calculate but want to know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea3c97f",
   "metadata": {},
   "source": [
    "Let's return to our hypothetical case. We have one sample of $n=35$ players, and one observed sample mean. Since, hypothetically, we don't know the population mean, can we give an interval where we think it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85656828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://matplotlib.org/stable/gallery/ticks/tick-formatters.html\n",
    "fig, ax = plt.subplots(figsize=(6.4, 0.4))\n",
    "\n",
    "# create number line by hiding unneeded elements of plot\n",
    "ax.yaxis.set_major_locator(ticker.NullLocator())\n",
    "for spine in ['left', 'right', 'top']:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "# set up number line limits\n",
    "ax.set_xlim(1000*((sample_mean-999)//1000), 1000*((sample_mean+1999)//1000))\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# set up number line tick marks\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1000))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(100))\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# plot sample mean\n",
    "ax.scatter(sample_mean, 0, s = 75, clip_on=False, zorder=10)\n",
    "ax.annotate(\n",
    "    '$\\overline{X}$',\n",
    "    xy = (sample_mean, 0),\n",
    "    xytext = (-4, 10),\n",
    "    textcoords = 'offset pixels',\n",
    "    fontsize = 'large',\n",
    ")\n",
    "\n",
    "# plot possible locations for population mean\n",
    "ax.annotate(\n",
    "    '$\\mu$?',\n",
    "    xy = (sample_mean+275, 0),\n",
    "    xytext = (-20, 50),\n",
    "    textcoords = 'offset pixels',\n",
    "    arrowprops = { 'arrowstyle': '->', 'shrinkA': 0, 'shrinkB': 5 },\n",
    "    fontsize = 'large',\n",
    ")\n",
    "ax.annotate(\n",
    "    '',\n",
    "    xy = (sample_mean-350, 0),\n",
    "    xytext = (sample_mean+175, 1.75),\n",
    "    arrowprops = { 'arrowstyle': '->', 'shrinkA': 7, 'shrinkB': 7 },\n",
    ")\n",
    "ax.annotate(\n",
    "    '',\n",
    "    xy = (sample_mean+500, 0),\n",
    "    xytext = (sample_mean+250, 1.75),\n",
    "    arrowprops = { 'arrowstyle': '->', 'shrinkA': 7, 'shrinkB': 7 },\n",
    ")\n",
    "ax.set_title('Sample Mean vs. Population Mean', y = 2.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d84d35",
   "metadata": {},
   "source": [
    "We know from above that there is a 95% probability that the interval $\\left(\\overline{X}-1.96 \\frac{\\sigma}{\\sqrt{n}}, \\overline{X} + 1.96  \\frac{\\sigma}{\\sqrt{n}}\\right)$ contains $\\mu$. Let's compute it!\n",
    "\n",
    "We have access to the sample mean $\\overline X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c169c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sample mean is {sample_mean:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55a6df",
   "metadata": {},
   "source": [
    "We don't know the population standard deviation $\\sigma$, but we might expect that the sample standard deviation $S$ is sufficiently close. If you don't believe that, we could also use a T-distribution, introduced in the next section. But in this case, our sample size is $n=35$, which is large enough to use $S$ in place of $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6971854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sample standard deviation is {sample_sd:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf6c19",
   "metadata": {},
   "source": [
    "Let's put it all together based on our formula above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "360a878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_ci = sample_mean - 1.96 * sample_sd / np.sqrt(35)\n",
    "upper_ci = sample_mean + 1.96 * sample_sd / np.sqrt(35)\n",
    "\n",
    "print(f\"95% confidence interval is ({lower_ci:.3f}, {upper_ci:.3f}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f82e05",
   "metadata": {},
   "source": [
    "We are 95% confident that the average weekly salary for premier league players falls in the interval we calculated. \n",
    "\n",
    "In our case, we actually have access to the real population parameter. Does our calculated interval actually contain the true population mean $\\mu$? Let's visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaf3a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot\n",
    "fig, ax = plt.subplots(figsize=(6.4, 0.4))\n",
    "ax.set_title(\"95% Confidence Interval\");\n",
    "\n",
    "# set up limits for x-axis (reference: https://stackoverflow.com/a/3411435)\n",
    "least = min([lower_ci, upper_ci, pop_mean])\n",
    "greatest = max([lower_ci, upper_ci, pop_mean])\n",
    "power_of_10 = int(math.floor(math.log10(abs(least))))\n",
    "get_bound = lambda x: int(round(x, -power_of_10))\n",
    "ax.set_xlim(get_bound(least) - 10**power_of_10, get_bound(greatest) + 10**power_of_10)\n",
    "\n",
    "# create number line by hiding unneeded elements of plot\n",
    "ax.yaxis.set_major_locator(ticker.NullLocator())\n",
    "for spine in ['left', 'right', 'top']:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "# set up number line tick marks (reference: https://matplotlib.org/stable/gallery/ticks/tick-formatters.html)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(10 ** power_of_10))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(10 ** (power_of_10-1)))\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# plot confidence interval\n",
    "ax.axvline(lower_ci, linestyle='dashed')\n",
    "ax.axvline(upper_ci, linestyle='dashed')\n",
    "ax.fill_between(x = np.linspace(lower_ci, upper_ci, 2), y1 = [0]*2, y2 = [1]*2, alpha=0.3)\n",
    "\n",
    "# plot and annotate sample and population means\n",
    "ax.scatter(pop_mean, 0, s = 75, clip_on=False, zorder=10)\n",
    "ax.annotate(\n",
    "    '$\\mu$',\n",
    "    xy = (pop_mean, 0),\n",
    "    xytext = (-4, 15),\n",
    "    textcoords = 'offset pixels',\n",
    "    fontsize = 'large',\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c059693",
   "metadata": {},
   "source": [
    "## Confidence Intervals in Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e3abb",
   "metadata": {},
   "source": [
    "We don't always have to calculate confidence intervals by hand. There are many Python libraries that will do this for you! One way is to use the `scipy.stats` library. We'll also find in other sections that much of the statistical inference code we run will automatically provide a confidence interval. The previous demonstrations will hopefully be helpful for you to know what's going on beneath the surface of the code and to give you a bit more *confidence* in the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e5838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = 0.95\n",
    "(lower_ci, upper_ci) = scipy.stats.norm.interval(\n",
    "    confidence_level,\n",
    "    loc=sample_mean,\n",
    "    scale=sample_sd/np.sqrt(35)\n",
    ")\n",
    "print(f\"95% confidence interval is ({lower_ci:.3f}, {upper_ci:.3f}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d292675f",
   "metadata": {},
   "source": [
    "Of course, 95% is not the only value we could use for the confidence level, though it is the most common. If we wanted to be more certain, we could increase that value. If precision was less important, we could decrease it. It all depends on the context in which you are working! \n",
    "\n",
    "In later sections, we will primarily compute confidence intervals for means using the T distribution, rather than the normal distribution. The difference between the intervals is discussed in those places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7e5a9",
   "metadata": {},
   "source": [
    "## Why Is It Called a Confidence Interval?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce8940",
   "metadata": {},
   "source": [
    "The number 95% is a probability, but it is not the probability that $\\mu$, the population mean, is in the interval. The population mean doesn't change, and hence it is either in the given interval or not---no probabilties involved! So what does the 95% confidence mean?\n",
    "\n",
    "The probability 95% concerns the interval itself, which depends on the data that we used. A different sample would give us different data, and hence a different interval. The \"confidence\" in \"95% confidence\" refers to the sampling process. Another way to say this is that 95% of all the possible confidence intervals we could construct in this way contain the true population mean.\n",
    "\n",
    "Since we have access to an entire population of footballers' salaries, we can take many samples and construct many sample means and confidence intervals. If we did this, how many would we expect to have the true average weekly salary (the population mean)?\n",
    "\n",
    "You can play around with the interactive widget below to explore this idea. Given a confidence level, the widget takes 25 random samples of size 35 from the salary data and plots a confidence interval for each one. (This widget is inspired by the OpenIntro [lab on confidence intervals](https://openintro.shinyapps.io/confidence_intervals/), which is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).)\n",
    "\n",
    "Drag the slider to select different confidence levels, and click the labels in the legend to hide or show different parts of the graph. Notice how different confidence levels result in different numbers of confidence intervals containing the population mean. (These numbers might not exactly match the confidence level, but that's because we're only constructing 25 confidence intervals, which is far short of the *total* number of possible confidence intervals we could construct.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5faea6e",
   "metadata": {
    "scrolled": false,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "sample_size = 35 # size of each sample\n",
    "num_samples = 25 # number of samples to take for each confidence level\n",
    "conflevels = np.arange(0.60, 1, 0.05) # confidence levels\n",
    "num_conflevels = len(conflevels)\n",
    "\n",
    "x_with_mu = [[] for i in range(num_conflevels)]\n",
    "x_without_mu = [[] for i in range(num_conflevels)]\n",
    "y_with_mu = [[] for i in range(num_conflevels)]\n",
    "y_without_mu = [[] for i in range(num_conflevels)]\n",
    "\n",
    "# for each confidence level in conflevels, generate confidence intervals\n",
    "# from num_samples samples of size sample_size, splitting them into\n",
    "# those containing mu and those not containing mu\n",
    "for i, conflevel in enumerate(conflevels):\n",
    "    for j in range(num_samples):\n",
    "        (lower_ci, upper_ci) = sm.stats.weightstats.zconfint(\n",
    "            x1 = salaries[\"Weekly Wages (GBP)\"].sample(sample_size),\n",
    "            alpha = 1-conflevel\n",
    "        )\n",
    "        if lower_ci <= pop_mean <= upper_ci:\n",
    "            x_with_mu[i].append([lower_ci, upper_ci])\n",
    "            y_with_mu[i].append([j,j])\n",
    "        else:\n",
    "            x_without_mu[i].append([lower_ci, upper_ci])\n",
    "            y_without_mu[i].append([j,j])\n",
    "\n",
    "# create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# set up colors (using default seaborn palette)\n",
    "plotly_palette = [f\"rgb({c[0]*256}, {c[1]*256}, {c[2]*256})\" for c in sns.color_palette()]\n",
    "confint_with_mu_color = plotly_palette[0]\n",
    "confint_without_mu_color = plotly_palette[3]\n",
    "mean_color = plotly_palette[1]\n",
    "\n",
    "# index of initially visible conflevel\n",
    "initial_conflevel = 0\n",
    "\n",
    "# for each confidence level\n",
    "for i in range(num_conflevels):\n",
    "    # add a trace for each confidence level containing mu\n",
    "    for j, (ci, y) in enumerate(zip(x_with_mu[i], y_with_mu[i])):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                visible = True if i == initial_conflevel else False,\n",
    "                x = ci,\n",
    "                y = y,\n",
    "                line = { 'color': confint_with_mu_color, 'width': 3 },\n",
    "                marker = { \"size\": 10 },\n",
    "                mode = 'lines+markers',\n",
    "                hovertemplate = '%{x:.2f}<extra></extra>',\n",
    "                name = 'confidence intervals<br>containing the<br>population mean',\n",
    "                legendgroup = f'{conflevels[i]}_with_mu', # group confidence intervals for this confidence level together\n",
    "                showlegend = True if j == 0 else False, # display legend entry only for first confidence interval\n",
    "            )\n",
    "        )\n",
    "    # add a trace for each confidence level not containing mu\n",
    "    for j, (ci, y) in enumerate(zip(x_without_mu[i], y_without_mu[i])):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                visible = True if i == initial_conflevel else False,\n",
    "                x = ci,\n",
    "                y = y,\n",
    "                line = { 'color': confint_without_mu_color, 'width': 3 },\n",
    "                marker = { \"size\": 10 },\n",
    "                mode = 'lines+markers',\n",
    "                hovertemplate = '%{x:.2f}<extra></extra>',\n",
    "                name = 'confidence intervals<br>not containing the<br>population mean',\n",
    "                legendgroup = f'{conflevels[i]}_without_mu', # group confidence intervals for this confidence level together\n",
    "                showlegend = True if j == 0 else False, # display legend entry only for first confidence interval\n",
    "            )\n",
    "        )\n",
    "\n",
    "# add trace for population mean\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        visible = True, # always visible\n",
    "        x = [pop_mean]*2,\n",
    "        y = [-1, num_samples],\n",
    "        marker = { 'size': 0 },\n",
    "        mode = 'lines',\n",
    "        line = { 'color': mean_color, 'width': 3.5, 'dash': 'dash' },\n",
    "        name = 'population mean',\n",
    "        legendrank = 0, # place first in legend\n",
    "        hoverinfo = 'none',\n",
    "    )\n",
    ")\n",
    "\n",
    "# get title for graph given index of confidence level\n",
    "def get_title(i):\n",
    "    num_with_mu = len(x_with_mu[i])\n",
    "    return (f'{num_samples} Confidence Intervals with {int(conflevels[i]*100)}% Confidence<br><br>' +\n",
    "        f'<sup>{num_with_mu} of the {num_samples} confidence intervals in this graph ' +\n",
    "        f'({(len(x_with_mu[i])/num_samples)*100:.0f}%) contain the population mean.</sup>')\n",
    "\n",
    "# create steps for the slider to select confidence level\n",
    "steps = []\n",
    "for i in range(num_conflevels):\n",
    "    steps.append({\n",
    "        'method': 'update',\n",
    "        'args': [ # arguments to pass to the update method\n",
    "            # update visibility so only the histogram and normal pdf for this sample size are visible\n",
    "            {\n",
    "                \"visible\": np.append(np.ravel([[True]*num_samples if i == j else [False]*num_samples for j in range(num_conflevels)]), True)\n",
    "            },\n",
    "            # update the title to reflect the change to the sample size\n",
    "            {\n",
    "                'title': get_title(i)\n",
    "            }\n",
    "        ],\n",
    "        'label': f'{int(conflevels[i]*100)}%',\n",
    "    })\n",
    "\n",
    "# create a slider using these steps and add it to fig\n",
    "fig.layout.sliders = [{\n",
    "    'active': initial_conflevel,\n",
    "    'currentvalue': {'prefix': 'Confidence Level: '},\n",
    "    'pad': {'t': 50},\n",
    "    'steps': steps,\n",
    "}]\n",
    "\n",
    "# set layout settings\n",
    "fig.update_layout(\n",
    "    title = {\n",
    "        \"x\": 0.5,\n",
    "        \"text\": get_title(initial_conflevel)\n",
    "    },\n",
    "    xaxis = { \"title\": \"Average Weekly Wages (GBP)\" },\n",
    "    yaxis = { \"visible\": False }, # hide y-axis\n",
    "    paper_bgcolor = \"LightSteelBlue\"\n",
    ")\n",
    "\n",
    "# show figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ddb0f",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Use the widget above to construct 25 different 90% confidence intervals for the average weekly wages of Premier League players. How many of the 25 contain the true population mean? Is this the number you expect? Would it be possible for exactly 90% of the intervals to contain the true population mean?\n",
    "\n",
    "2. Choose your own confidence level, and construct a single confidence interval for the average weekly wages of a Premier League player. Describe your interval in a complete sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1115c7a",
   "metadata": {},
   "source": [
    "## The Central Limit Theorem for Discrete Numerical Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a207bce",
   "metadata": {},
   "source": [
    "Finally, we want to note that this theory holds for any numerical distribution, even one that is discrete!  In the widget below, we demonstrate the CLT for discrete distributions by approximating the sample average of a number of dice rolls.\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src='https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/2-Dice-Icon.svg/240px-2-Dice-Icon.svg.png' alt='Dice icon by Steaphan Greene, licensed under CC BY-SA 3.0.'>\n",
    "    <figcaption>Dice icon by Steaphan Greene, licensed under CC BY-SA 3.0.</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Given a sample size, the widget simulates rolling a die that many times and then takes the average of the rolls. It does this 10000 times and then plots the histogram of the resulting averages, overlaid with the normal distribution with the same mean and standard deviation.\n",
    "\n",
    "Drag the slider to select different sample sizes, and click the labels in the legend to hide or show different parts of the graph. Notice how the histogram of the averages fits the normal distribution more closely as the sample size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c0516",
   "metadata": {
    "scrolled": false,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Outcomes of rolling a die\n",
    "die_outcomes = pd.DataFrame(np.arange(1, 7))\n",
    "\n",
    "# Get the average of reps samples from data with the given sample size and replacement policy\n",
    "def get_sample_avg(data, size, reps, replace=False):\n",
    "    return [np.mean(data.sample(size, replace=replace).to_numpy()) for i in range(reps)]\n",
    "\n",
    "# Define sample sizes and number of repetitions for sampling\n",
    "sample_sizes = np.arange(1, 11, 1)\n",
    "n = len(sample_sizes)\n",
    "reps = 10000\n",
    "\n",
    "# Use default seaborn palette (reference: https://josephlemaitre.com/2022/06/use-a-seaborn-color-palette-for-plotly-figures/)\n",
    "plotly_palette = iter([f\"rgb({c[0]*256}, {c[1]*256}, {c[2]*256})\" for c in sns.color_palette()])\n",
    "histcolor = next(plotly_palette)\n",
    "normcolor = next(plotly_palette)\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Set consistent limits for axes in all traces\n",
    "xlim = (1, 6)\n",
    "ylim = (0, 1)\n",
    "\n",
    "# Define which sample size will be initially visible\n",
    "# (note that this is the index of the sample size)\n",
    "initial_sample_size_index = 0\n",
    "\n",
    "get_title = lambda i: f\"Averages of {reps} Random Samples of Size {sample_sizes[i]}\"\n",
    "\n",
    "# Get averages for all possible sample sizes\n",
    "# averages[i] is the average of reps samples of size sample_sizes[i] (with replacement)\n",
    "averages = [get_sample_avg(die_outcomes, size, reps, replace=True) for size in sample_sizes]\n",
    "\n",
    "# Add histogram traces\n",
    "# (the histogram for averages[i] is plotted as the ith trace, fig.data[i])\n",
    "for i, avg in enumerate(averages):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            # initially, only the histogram for initial_sample_size should be visible\n",
    "            visible = True if i == initial_sample_size_index else False,\n",
    "            name = \"histogram<br>of averages\", # label for legend\n",
    "            x = avg,\n",
    "            marker = { \"color\": histcolor },\n",
    "            hoverinfo = \"x+y\",\n",
    "            xbins = {\"size\" : 1/(i+1)},\n",
    "            histnorm = \"probability density\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add normal pdf traces\n",
    "# (the normal pdf for averages[i] is plotted as the (i+n)th trace, fig.data[i+n])\n",
    "for i, avg in enumerate(averages):\n",
    "    # determine x-axis limits\n",
    "    if xlim is not None:\n",
    "        x = np.linspace(*xlim, 100)\n",
    "    else:\n",
    "        # use the same x-axis limits as averages[i]\n",
    "        x = np.linspace(min(fig.data[i].x), max(fig.data[i].x), 100)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            # initially, only the normal pdf for initial_sample_size should be visible\n",
    "            visible = True if i == initial_sample_size_index else False,\n",
    "            line = { \"width\": 6 },\n",
    "            name = \"normal<br>distribution\", # label for legend\n",
    "            x = x,\n",
    "            y = scipy.stats.norm.pdf(x, np.mean(avg), np.std(avg)),\n",
    "            marker = { \"color\": normcolor },\n",
    "            hoverinfo = \"x+y\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Create steps for the slider to select sample size\n",
    "steps = []\n",
    "for i in range(n):\n",
    "    steps.append({\n",
    "        \"method\": \"update\",\n",
    "        \"args\": [ # arguments to pass to the update method\n",
    "            # update visibility so only the histogram and normal pdf for this sample size are visible\n",
    "            { \"visible\": [True if (j == i or j-n == i) else False for j in range(len(fig.data))] },\n",
    "            # update the title to reflect the change to the sample size\n",
    "            { \"title\": get_title(i) }\n",
    "        ],\n",
    "        \"label\": str(sample_sizes[i]),\n",
    "    })\n",
    "\n",
    "# Create a slider using these steps and add it to fig\n",
    "fig.layout.sliders = [{\n",
    "    \"active\": initial_sample_size_index,\n",
    "    \"currentvalue\": {\"prefix\": \"Sample Size: \"},\n",
    "    \"pad\": {\"t\": 50},\n",
    "    \"steps\": steps,\n",
    "}]\n",
    "\n",
    "# Set layout settings\n",
    "fig.update_layout(\n",
    "    title = {\n",
    "        \"x\": 0.5,\n",
    "        \"text\": get_title(initial_sample_size_index)\n",
    "    },\n",
    "    xaxis = {\n",
    "        \"title\": \"Average Die Outcome\",\n",
    "        \"range\": xlim,\n",
    "        \"constrain\": \"domain\",\n",
    "    },\n",
    "    yaxis = {\n",
    "        \"title\": \"Probability Density\",\n",
    "        \"range\": ylim,\n",
    "        \"constrain\": \"domain\",\n",
    "    },\n",
    "    paper_bgcolor = \"LightSteelBlue\"\n",
    ")\n",
    "\n",
    "# Display figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e495117",
   "metadata": {},
   "source": [
    "## Confidence Intervals for Differences of Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab6557",
   "metadata": {},
   "source": [
    "Coming soon: Lab or exercises, with some theory walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346cd29",
   "metadata": {},
   "source": [
    "## Confidence Intervals for Categorical Data/Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a0496",
   "metadata": {},
   "source": [
    "We can also calculate confidence intervals for population proportions and differences of proportions. We'll explore that in the next section alongside hypothesis testing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
